{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbasecondabd50bd29c9084c3dacc271a23f266570",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titanic Data Challenge\n",
    "\n",
    "## Introduction\n",
    "**Kaggle Description**: \n",
    "> On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n",
    "\n",
    "> While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
    "\n",
    "> In this challenge, we ask you to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc).\n",
    "\n",
    "**Goal**: To predict whether or not a passenger will survive the sinking of the Titanic based on provided information\n",
    "\n",
    "Let's begin! First, let's do some boilerplate setup."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\u001b[32mAll Modules Imported!\u001b[0m\n"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# custom helpers\n",
    "from helpers.helper import get_splits\n",
    "# data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# output\n",
    "from termcolor import cprint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cprint('All Modules Imported!', 'green')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\u001b[32mData Imported!\u001b[0m\n\u001b[36mTraining Data Example:\u001b[0m\n"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>887</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Montvila, Rev. Juozas</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>211536</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Graham, Miss. Margaret Edith</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112053</td>\n      <td>30.0000</td>\n      <td>B42</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <td>889</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>W./C. 6607</td>\n      <td>23.4500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <td>890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Behr, Mr. Karl Howell</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111369</td>\n      <td>30.0000</td>\n      <td>C148</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <td>891</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Dooley, Mr. Patrick</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>370376</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows × 11 columns</p>\n</div>",
      "text/plain": "             Survived  Pclass  \\\nPassengerId                     \n1                   0       3   \n2                   1       1   \n3                   1       3   \n4                   1       1   \n5                   0       3   \n...               ...     ...   \n887                 0       2   \n888                 1       1   \n889                 0       3   \n890                 1       1   \n891                 0       3   \n\n                                                          Name     Sex   Age  \\\nPassengerId                                                                    \n1                                      Braund, Mr. Owen Harris    male  22.0   \n2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n3                                       Heikkinen, Miss. Laina  female  26.0   \n4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n5                                     Allen, Mr. William Henry    male  35.0   \n...                                                        ...     ...   ...   \n887                                      Montvila, Rev. Juozas    male  27.0   \n888                               Graham, Miss. Margaret Edith  female  19.0   \n889                   Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN   \n890                                      Behr, Mr. Karl Howell    male  26.0   \n891                                        Dooley, Mr. Patrick    male  32.0   \n\n             SibSp  Parch            Ticket     Fare Cabin Embarked  \nPassengerId                                                          \n1                1      0         A/5 21171   7.2500   NaN        S  \n2                1      0          PC 17599  71.2833   C85        C  \n3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n4                1      0            113803  53.1000  C123        S  \n5                0      0            373450   8.0500   NaN        S  \n...            ...    ...               ...      ...   ...      ...  \n887              0      0            211536  13.0000   NaN        S  \n888              0      0            112053  30.0000   B42        S  \n889              1      2        W./C. 6607  23.4500   NaN        S  \n890              0      0            111369  30.0000  C148        C  \n891              0      0            370376   7.7500   NaN        Q  \n\n[891 rows x 11 columns]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = pd.read_csv('./data/train.csv', index_col='PassengerId')\n",
    "test_data = pd.read_csv('./data/test.csv', index_col='PassengerId')\n",
    "\n",
    "cprint('Data Imported!', 'green')\n",
    "cprint('Training Data Example:', 'cyan')\n",
    "display(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Process\n",
    "1. Figure out which features we can safely drop/keep.\n",
    "2. Encode features that need encoding (label encoding, categorical encoding).\n",
    "3. Start feature engineering some new columns so we have a wider predicition set. \n",
    "4. Do feature selection to determine which features are not needed and find the best combination of features to use.\n",
    "5. Research and test what models would be best for our situation and train/test different models.\n",
    "6. Train and predict on the train/test sets.\n",
    "7. Finally, output everything to a new CSV.\n",
    "\n",
    "## Tools\n",
    "Our current model options are: LightGBM, RandomForestRegressor, ExtraTreesRegressor.\n",
    "\n",
    "I also want to use a pipeline to keep everything organized into various steps.\n",
    "\n",
    "\n",
    "## Getting Started\n",
    "### Feature Engineering\n",
    "So the columns we have are:\n",
    "\n",
    "| Variable | Definition | Key |\n",
    "| ----- | --- | --- |\n",
    "| survival | Survived or not | 0 = No, 1 = Yes |\n",
    "| pclass | Ticket class | 1 = 1st, 2 = 2nd, 3 = 3rd |\n",
    "| sex | Sex | |\n",
    "| age | Age in years | |\n",
    "| sibsp | Num of siblings / spouses aboard | |\n",
    "| parch | Num of parents / children aboard | |\n",
    "| ticket | Ticket number | |\n",
    "| fare | Passengar fare | |\n",
    "| cabin | Cabin number | |\n",
    "| embarked | Port of embarkation |   C = Cherbourg, Q = Queenstown, S = Southampton |\n",
    "\n",
    "Looking at these descriptions, we can probably disregard\n",
    "- Name\n",
    "- Ticket number\n",
    "\n",
    "Ticket number is a ... maybe, as we aren't entirely sure how ticket numbers are handed out.\n",
    "\n",
    "Let's get to engineering.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Createion Steps\n",
    "1. [x] Choose feature cols based on feature table and relevant data\n",
    "2. [x] Split into train/valid/test sets\n",
    "3. [ ] Generate features\n",
    "    1. Interactions\n",
    "    2. ...\n",
    "4. [ ] Setup pipeline\n",
    "    1. [x] Imputation to fill in N/A values\n",
    "    2. [x] Categorical encoding, CatBoost\n",
    "    4. [x] Standardize values\n",
    "    5. [ ] Feature Selection\n",
    "5. [ ] Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns overlap but no suffix specified: Index(['Pclass_Sex', 'Pclass_Cabin', 'Pclass_Embarked', 'Sex_Cabin',\n       'Sex_Embarked', 'Cabin_Embarked'],\n      dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-02e40cdc9f05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0minteractions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_feat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcomb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcomb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mcategorical_cols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteractions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# 2. Split sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   7244\u001b[0m         \u001b[0;31m# For SparseDataFrame's benefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7245\u001b[0m         return self._join_compat(\n\u001b[0;32m-> 7246\u001b[0;31m             \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlsuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrsuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7247\u001b[0m         )\n\u001b[1;32m   7248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   7267\u001b[0m                 \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7268\u001b[0m                 \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7269\u001b[0;31m                 \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7270\u001b[0m             )\n\u001b[1;32m   7271\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     )\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         llabels, rlabels = _items_overlap_with_suffix(\n\u001b[0;32m--> 648\u001b[0;31m             \u001b[0mldata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m         )\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_items_overlap_with_suffix\u001b[0;34m(left, lsuffix, right, rsuffix)\u001b[0m\n\u001b[1;32m   2009\u001b[0m         raise ValueError(\n\u001b[1;32m   2010\u001b[0m             \u001b[0;34m\"columns overlap but no suffix specified: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m             \u001b[0;34m\"{rename}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_rename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2012\u001b[0m         )\n\u001b[1;32m   2013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: columns overlap but no suffix specified: Index(['Pclass_Sex', 'Pclass_Cabin', 'Pclass_Embarked', 'Sex_Cabin',\n       'Sex_Embarked', 'Cabin_Embarked'],\n      dtype='object')"
     ]
    }
   ],
   "source": [
    "# 1. Choose our feature cols based on feature table above\n",
    "numerical_cols = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "categorical_cols = ['Pclass', 'Sex', 'Cabin', 'Embarked']\n",
    "target_col = 'Survived'\n",
    "# Let's make some features\n",
    "from itertools import combinations\n",
    "\n",
    "interactions = pd.DataFrame(index=train.index)\n",
    "for comb in combinations(categorical_cols, 2):\n",
    "    new_feat = comb[0] + \"_\" + comb[1]\n",
    "    interactions[new_feat] = train[comb[0]].astype(str) + \"_\" + train[comb[1]].astype(str)\n",
    "    categorical_cols.append(new_feat)\n",
    "train_data = train_data.join(interactions)\n",
    "display(train_data)\n",
    "# 2. Split sets\n",
    "train, valid, _ = get_splits(train_data)\n",
    "X_train = train.drop([target_col], axis=1)\n",
    "y_train = train[target_col]\n",
    "X_valid = valid.drop([target_col], axis=1)\n",
    "y_valid = valid[target_col]\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature Generation / Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Pclass_Sex</th>\n      <th>Pclass_Cabin</th>\n      <th>Pclass_Embarked</th>\n      <th>Sex_Cabin</th>\n      <th>Sex_Embarked</th>\n      <th>Cabin_Embarked</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>3_male</td>\n      <td>3_nan</td>\n      <td>3_S</td>\n      <td>male_nan</td>\n      <td>male_S</td>\n      <td>nan_S</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n      <td>1_female</td>\n      <td>1_C85</td>\n      <td>1_C</td>\n      <td>female_C85</td>\n      <td>female_C</td>\n      <td>C85_C</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>3_female</td>\n      <td>3_nan</td>\n      <td>3_S</td>\n      <td>female_nan</td>\n      <td>female_S</td>\n      <td>nan_S</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n      <td>1_female</td>\n      <td>1_C123</td>\n      <td>1_S</td>\n      <td>female_C123</td>\n      <td>female_S</td>\n      <td>C123_S</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>3_male</td>\n      <td>3_nan</td>\n      <td>3_S</td>\n      <td>male_nan</td>\n      <td>male_S</td>\n      <td>nan_S</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>709</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cleaver, Miss. Alice</td>\n      <td>female</td>\n      <td>22.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>113781</td>\n      <td>151.5500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>1_female</td>\n      <td>1_nan</td>\n      <td>1_S</td>\n      <td>female_nan</td>\n      <td>female_S</td>\n      <td>nan_S</td>\n    </tr>\n    <tr>\n      <td>710</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Moubarek, Master. Halim Gonios (\"William George\")</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2661</td>\n      <td>15.2458</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>3_male</td>\n      <td>3_nan</td>\n      <td>3_C</td>\n      <td>male_nan</td>\n      <td>male_C</td>\n      <td>nan_C</td>\n    </tr>\n    <tr>\n      <td>711</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Mayne, Mlle. Berthe Antonine (\"Mrs de Villiers\")</td>\n      <td>female</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>PC 17482</td>\n      <td>49.5042</td>\n      <td>C90</td>\n      <td>C</td>\n      <td>1_female</td>\n      <td>1_C90</td>\n      <td>1_C</td>\n      <td>female_C90</td>\n      <td>female_C</td>\n      <td>C90_C</td>\n    </tr>\n    <tr>\n      <td>712</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Klaber, Mr. Herman</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>113028</td>\n      <td>26.5500</td>\n      <td>C124</td>\n      <td>S</td>\n      <td>1_male</td>\n      <td>1_C124</td>\n      <td>1_S</td>\n      <td>male_C124</td>\n      <td>male_S</td>\n      <td>C124_S</td>\n    </tr>\n    <tr>\n      <td>713</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Taylor, Mr. Elmer Zebley</td>\n      <td>male</td>\n      <td>48.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>19996</td>\n      <td>52.0000</td>\n      <td>C126</td>\n      <td>S</td>\n      <td>1_male</td>\n      <td>1_C126</td>\n      <td>1_S</td>\n      <td>male_C126</td>\n      <td>male_S</td>\n      <td>C126_S</td>\n    </tr>\n  </tbody>\n</table>\n<p>713 rows × 17 columns</p>\n</div>",
      "text/plain": "             Survived  Pclass  \\\nPassengerId                     \n1                   0       3   \n2                   1       1   \n3                   1       3   \n4                   1       1   \n5                   0       3   \n...               ...     ...   \n709                 1       1   \n710                 1       3   \n711                 1       1   \n712                 0       1   \n713                 1       1   \n\n                                                          Name     Sex   Age  \\\nPassengerId                                                                    \n1                                      Braund, Mr. Owen Harris    male  22.0   \n2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n3                                       Heikkinen, Miss. Laina  female  26.0   \n4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n5                                     Allen, Mr. William Henry    male  35.0   \n...                                                        ...     ...   ...   \n709                                       Cleaver, Miss. Alice  female  22.0   \n710          Moubarek, Master. Halim Gonios (\"William George\")    male   NaN   \n711           Mayne, Mlle. Berthe Antonine (\"Mrs de Villiers\")  female  24.0   \n712                                         Klaber, Mr. Herman    male   NaN   \n713                                   Taylor, Mr. Elmer Zebley    male  48.0   \n\n             SibSp  Parch            Ticket      Fare Cabin Embarked  \\\nPassengerId                                                            \n1                1      0         A/5 21171    7.2500   NaN        S   \n2                1      0          PC 17599   71.2833   C85        C   \n3                0      0  STON/O2. 3101282    7.9250   NaN        S   \n4                1      0            113803   53.1000  C123        S   \n5                0      0            373450    8.0500   NaN        S   \n...            ...    ...               ...       ...   ...      ...   \n709              0      0            113781  151.5500   NaN        S   \n710              1      1              2661   15.2458   NaN        C   \n711              0      0          PC 17482   49.5042   C90        C   \n712              0      0            113028   26.5500  C124        S   \n713              1      0             19996   52.0000  C126        S   \n\n            Pclass_Sex Pclass_Cabin Pclass_Embarked    Sex_Cabin Sex_Embarked  \\\nPassengerId                                                                     \n1               3_male        3_nan             3_S     male_nan       male_S   \n2             1_female        1_C85             1_C   female_C85     female_C   \n3             3_female        3_nan             3_S   female_nan     female_S   \n4             1_female       1_C123             1_S  female_C123     female_S   \n5               3_male        3_nan             3_S     male_nan       male_S   \n...                ...          ...             ...          ...          ...   \n709           1_female        1_nan             1_S   female_nan     female_S   \n710             3_male        3_nan             3_C     male_nan       male_C   \n711           1_female        1_C90             1_C   female_C90     female_C   \n712             1_male       1_C124             1_S    male_C124       male_S   \n713             1_male       1_C126             1_S    male_C126       male_S   \n\n            Cabin_Embarked  \nPassengerId                 \n1                    nan_S  \n2                    C85_C  \n3                    nan_S  \n4                   C123_S  \n5                    nan_S  \n...                    ...  \n709                  nan_S  \n710                  nan_C  \n711                  C90_C  \n712                 C124_S  \n713                 C126_S  \n\n[713 rows x 17 columns]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's make some features\n",
    "from itertools import combinations\n",
    "\n",
    "interactions = pd.DataFrame(index=train.index)\n",
    "for comb in combinations(categorical_cols, 2):\n",
    "    new_feat = comb[0] + \"_\" + comb[1]\n",
    "    interactions[new_feat] = train[comb[0]].astype(str) + \"_\" + train[comb[1]].astype(str)\n",
    "tester = train.join(interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/Users/tyler.welsh/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\nThis means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\nInstead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\nYou can install the OpenMP library by the following command: ``brew install libomp``.\n  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
    }
   ],
   "source": [
    "# machine learning\n",
    "from sklearn import feature_selection\n",
    "from sklearn import preprocessing\n",
    "# Pipeline code originally copied from 3_intermediate_training_summary\n",
    "from helpers.helper import PipelineFS\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# conda install -c conda-forge category_encoders\n",
    "from category_encoders import CatBoostEncoder\n",
    "# conda install -c conda-forge lightgbm\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lgb_pipeline_score(X, y, params={'n_estimators':10,'num_leaves':64,'rate':0.1,'early_stopping_rounds':10}):\n",
    "    \"\"\"\n",
    "\n",
    "    params: Python object of params with the following keys\n",
    "        n_estimators: number of estimators to use in pipeline, Default: 10\n",
    "        num_leaves: num_leaves in lgb model, Default: 64\n",
    "        rate: learning rate, Default: 0.1\n",
    "        early_stopping_rounds: how many rounds to stop after if low variance, Default: 10\n",
    "    \"\"\"\n",
    "    # Preprocessing for numerical data (fill in NA)\n",
    "    numerical_transformer = PipelineFS(\n",
    "        steps=[\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Preprocessing for categorical data\n",
    "    categorical_transformer = PipelineFS(\n",
    "        steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('catboost', CatBoostEncoder())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Bundle preprocessing for numerical and categorical data\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model = lgb.LGBMClassifier(n_estimators=params['n_estimators'], num_leaves=params['num_leaves'], learning_rate=params['rate'])\n",
    "\n",
    "    # Bundle preprocessing and modeling code in a pipeline\n",
    "    my_pipeline = PipelineFS(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', model)\n",
    "        ],\n",
    "        verbose=True\n",
    "    )\n",
    "    # Preprocessing of training data, fit model \n",
    "    # my_pipeline.fit(X_train, y_train)\n",
    "    # cprint('Fit!', 'green')\n",
    "    # Preprocessing of validation data, get predictions\n",
    "    scores = cross_val_score(my_pipeline, X, y, cv=5)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'helpers.helper.PipelineFS'>\n[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.2s\n[Pipeline] ............. (step 2 of 2) Processing model, total=   0.1s\n<class 'helpers.helper.PipelineFS'>\n[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.1s\n[Pipeline] ............. (step 2 of 2) Processing model, total=   0.2s\n<class 'helpers.helper.PipelineFS'>\n[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.1s\n[Pipeline] ............. (step 2 of 2) Processing model, total=   0.1s\n<class 'helpers.helper.PipelineFS'>\n[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.1s\n[Pipeline] ............. (step 2 of 2) Processing model, total=   0.0s\n<class 'helpers.helper.PipelineFS'>\n[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.1s\n[Pipeline] ............. (step 2 of 2) Processing model, total=   0.1s\n"
    },
    {
     "data": {
      "text/plain": "0.6943312007141794"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lgb_pipeline_score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}