{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbaseconda973ef65525d24389916660910d6d08ff",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titanic Data Challenge\n",
    "\n",
    "## Introduction\n",
    "**Kaggle Description**: \n",
    "> On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n",
    "\n",
    "> While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
    "\n",
    "> In this challenge, we ask you to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc).\n",
    "\n",
    "**Goal**: To predict whether or not a passenger will survive the sinking of the Titanic based on provided information\n",
    "\n",
    "Let's begin! First, let's do some boilerplate setup."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\u001b[32mAll Modules Imported!\u001b[0m\n"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# custom helpers\n",
    "from helpers.helper import get_splits\n",
    "# data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# output\n",
    "from termcolor import cprint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cprint('All Modules Imported!', 'green')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\u001b[32mData Imported!\u001b[0m\n\u001b[36mTraining Data Example:\u001b[0m\n"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>887</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Montvila, Rev. Juozas</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>211536</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Graham, Miss. Margaret Edith</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112053</td>\n      <td>30.0000</td>\n      <td>B42</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <td>889</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>W./C. 6607</td>\n      <td>23.4500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <td>890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Behr, Mr. Karl Howell</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111369</td>\n      <td>30.0000</td>\n      <td>C148</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <td>891</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Dooley, Mr. Patrick</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>370376</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows × 11 columns</p>\n</div>",
      "text/plain": "             Survived  Pclass  \\\nPassengerId                     \n1                   0       3   \n2                   1       1   \n3                   1       3   \n4                   1       1   \n5                   0       3   \n...               ...     ...   \n887                 0       2   \n888                 1       1   \n889                 0       3   \n890                 1       1   \n891                 0       3   \n\n                                                          Name     Sex   Age  \\\nPassengerId                                                                    \n1                                      Braund, Mr. Owen Harris    male  22.0   \n2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n3                                       Heikkinen, Miss. Laina  female  26.0   \n4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n5                                     Allen, Mr. William Henry    male  35.0   \n...                                                        ...     ...   ...   \n887                                      Montvila, Rev. Juozas    male  27.0   \n888                               Graham, Miss. Margaret Edith  female  19.0   \n889                   Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN   \n890                                      Behr, Mr. Karl Howell    male  26.0   \n891                                        Dooley, Mr. Patrick    male  32.0   \n\n             SibSp  Parch            Ticket     Fare Cabin Embarked  \nPassengerId                                                          \n1                1      0         A/5 21171   7.2500   NaN        S  \n2                1      0          PC 17599  71.2833   C85        C  \n3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n4                1      0            113803  53.1000  C123        S  \n5                0      0            373450   8.0500   NaN        S  \n...            ...    ...               ...      ...   ...      ...  \n887              0      0            211536  13.0000   NaN        S  \n888              0      0            112053  30.0000   B42        S  \n889              1      2        W./C. 6607  23.4500   NaN        S  \n890              0      0            111369  30.0000  C148        C  \n891              0      0            370376   7.7500   NaN        Q  \n\n[891 rows x 11 columns]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(891, 11)\n"
    }
   ],
   "source": [
    "train_data = pd.read_csv('./data/train.csv', index_col='PassengerId')\n",
    "test_data = pd.read_csv('./data/test.csv', index_col='PassengerId')\n",
    "\n",
    "cprint('Data Imported!', 'green')\n",
    "cprint('Training Data Example:', 'cyan')\n",
    "display(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Process\n",
    "1. Figure out which features we can safely drop/keep.\n",
    "2. Encode features that need encoding (label encoding, categorical encoding).\n",
    "3. Start feature engineering some new columns so we have a wider predicition set. \n",
    "4. Do feature selection to determine which features are not needed and find the best combination of features to use.\n",
    "5. Research and test what models would be best for our situation and train/test different models.\n",
    "6. Train and predict on the train/test sets.\n",
    "7. Finally, output everything to a new CSV.\n",
    "\n",
    "## Tools\n",
    "Our current model options are: LightGBM, RandomForestRegressor, ExtraTreesRegressor.\n",
    "\n",
    "I also want to use a pipeline to keep everything organized into various steps.\n",
    "\n",
    "\n",
    "## Getting Started\n",
    "### Feature Engineering\n",
    "So the columns we have are:\n",
    "\n",
    "| Variable | Definition | Key |\n",
    "| ----- | --- | --- |\n",
    "| survival | Survived or not | 0 = No, 1 = Yes |\n",
    "| pclass | Ticket class | 1 = 1st, 2 = 2nd, 3 = 3rd |\n",
    "| sex | Sex | |\n",
    "| age | Age in years | |\n",
    "| sibsp | Num of siblings / spouses aboard | |\n",
    "| parch | Num of parents / children aboard | |\n",
    "| ticket | Ticket number | |\n",
    "| fare | Passengar fare | |\n",
    "| cabin | Cabin number | |\n",
    "| embarked | Port of embarkation |   C = Cherbourg, Q = Queenstown, S = Southampton |\n",
    "\n",
    "Looking at these descriptions, we can probably disregard\n",
    "- Name\n",
    "- Ticket number\n",
    "\n",
    "Ticket number is a ... maybe, as we aren't entirely sure how ticket numbers are handed out.\n",
    "\n",
    "Let's get to engineering.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Createion Steps\n",
    "1. [x] Choose feature cols based on feature table and relevant data\n",
    "2. [x] Split into train/valid/test sets\n",
    "3. [ ] Generate features\n",
    "    1. Interactions\n",
    "    2. ...\n",
    "4. [ ] Setup pipeline\n",
    "    1. [x] Imputation to fill in N/A values\n",
    "    2. [x] Categorical encoding, CatBoost\n",
    "    4. [x] Standardize values\n",
    "    5. [ ] Feature Selection\n",
    "5. [ ] Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Choose our feature cols based on feature table above\n",
    "numerical_cols = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "categorical_cols = ['Pclass', 'Sex', 'Cabin', 'Embarked']\n",
    "target_col = 'Survived'\n",
    "# 2. Split sets\n",
    "train, valid, _ = get_splits(train_data)\n",
    "X_train = train.drop([target_col], axis=1)\n",
    "y_train = train[target_col]\n",
    "X_valid = valid.drop([target_col], axis=1)\n",
    "y_valid = valid[target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature Generation / Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make some features"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning\n",
    "from sklearn import feature_selection\n",
    "from sklearn import preprocessing\n",
    "# Pipeline code originally copied from 3_intermediate_training_summary\n",
    "from helpers.helper import PipelineFS\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# conda install -c conda-forge category_encoders\n",
    "from category_encoders import CatBoostEncoder\n",
    "# conda install -c conda-forge lightgbm\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.1s\n[Pipeline] ............. (step 2 of 2) Processing model, total=   0.2s\n\u001b[32mFit!\u001b[0m\n"
    }
   ],
   "source": [
    "# Preprocessing for numerical data (fill in NA)\n",
    "numerical_transformer = PipelineFS(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = PipelineFS(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('catboost', CatBoostEncoder())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "num_leaves = 64\n",
    "learning_rate = 0.1\n",
    "early_stopping_rounds = 10\n",
    "\n",
    "model = lgb.LGBMClassifier(num_leaves=num_leaves, learning_rate=learning_rate)\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "my_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ],\n",
    "    verbose=True\n",
    ")\n",
    "# Preprocessing of training data, fit model \n",
    "# my_pipeline.fit(X_train, y_train)\n",
    "# cprint('Fit!', 'green')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.1s\n[Pipeline] ............. (step 2 of 2) Processing model, total=   0.0s\n[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.1s\n[Pipeline] ............. (step 2 of 2) Processing model, total=   0.0s\n[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.1s\n[Pipeline] ............. (step 2 of 2) Processing model, total=   0.0s\n[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.1s\n[Pipeline] ............. (step 2 of 2) Processing model, total=   0.0s\n[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.1s\n[Pipeline] ............. (step 2 of 2) Processing model, total=   0.0s\n"
    },
    {
     "data": {
      "text/plain": "array([0.64335664, 0.60839161, 0.79020979, 0.76223776, 0.75886525])"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing of validation data, get predictions\n",
    "scores = cross_val_score(my_pipeline, X_train, y_train, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "score = mean_absolute_error(y_valid, preds)\n",
    "print('MAE:', score)\n",
    "\n",
    "# Use cross_val_score from skikit-learn to make cross validation easy!\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Multiply by -1 since sklearn calculates *negative* MAE\n",
    "scores = -1 * cross_val_score(\n",
    "    my_pipeline, X, y,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_absolute_error'\n",
    ")"
   ]
  }
 ]
}