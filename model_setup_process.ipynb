{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Science Project Setup Process\n",
    "\n",
    "This notebook will go over the general process of setting up data science projects for future models"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Import and Analyze the Data\n",
    "Our first step will be to import the training (and test) data and start analyizing the data. What we need to focus on is:\n",
    "- Which features (columns) will be good for our model, and which are unneeded?\n",
    "- How should we handle NaN values?\n",
    "- Do we have categorical data? How should we handle it.\n",
    "\n",
    "## 2. Decide Preprocessing Steps\n",
    "After analyzing our data and figuring out what we need to cut/change, we go forward with preprocessing. This includes:\n",
    "- Imputing NaN values for both numeric and categorical columns\n",
    "- Handling categorical data (dropping/one-hot encoding)\n",
    "\n",
    "## 3. Setup model\n",
    "After analyizing our data and setting up preprocessing, it's time to setup our model, choosing some starting parameters and which variables we will need to change for optimization.\n",
    "\n",
    "## 4. Pipeline Setup\n",
    "After figuring out our preprocessing and model setup, it's time to plug them into a pipeline to get ready for testing! Generally we will go with this setup:\n",
    "```python\n",
    "numerical_transformer = SimpleImputer(strategy='mean')\n",
    "categorical_transform = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),     # transform the numerical_cols with the numerical transformer\n",
    "        ('cat', categorical_transform, categorical_cols)    # transform the categorical_cols with the categorical transformer\n",
    "    ]\n",
    ")\n",
    "\n",
    "## 5. Define our model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "# Setup our pipeline\n",
    "my_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "```\n",
    "\n",
    "## 6. Training and Tweaking Time!\n",
    "With the pipeline setup, it's time to start training and testing our model. With cross validation, this is when we'll start tweaking things to get better scores. Some things to tweak include:\n",
    "- Model's variables (n-estimators, etc)\n",
    "- Model features\n",
    "- Training size\n",
    "\n",
    "## 7. Make predictions and continue tweaking!\n",
    "When we feel we've finally gotten a good MAE score and our model is looking good, it's time to start making final predictions! And occasionally tweak things if we feel it good be better."
   ]
  }
 ]
}