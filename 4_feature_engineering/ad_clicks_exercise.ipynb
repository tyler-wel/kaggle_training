{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering Ad Clicks Exercise\n",
    "\n",
    "The dataset we will be using for this exercise is a sample from 'TalkingData AdTracking' Kaggle competition. All positive samples (where is_attributed == 1) was kept, while 99% of negative samples we're discarded. This sample has roughly 20% positive examples.\n",
    "The data has the following features: (note id, app, device, os, and channel are encoded).\n",
    "\n",
    "The overall goal is to predict whether a user will download an app after clicking a mobile ad.\n",
    "\n",
    "[1. Baseline Modeling](#baseline)  \n",
    "[2. Categorical Encoding](#encode)  \n",
    "[3. Feature Generation](#generate)  \n",
    "[4. Feature Selection](#select)\n",
    "\n",
    "\n",
    "#### Note to self:\n",
    "- **click_data** is the raw imported data\n",
    "- **clicks** is timestamp and label encoded\n",
    "\n",
    "<a id='baseline'></a>\n",
    "## 1. Baseline Modeling\n",
    "Using what we learned in the overview, let's setup our baseline model.\n"
   ]
  },
  {
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from my_modules import data_imports as data\n",
    "from my_modules import feature_engineering as fe\n",
    "from termcolor import colored, cprint\n",
    "\n",
    "click_data = data.import_ad_clicks_data()\n",
    "click_data.head(10)\n",
    "\n",
    "score_dict = {}"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[32mAd Click data imported\u001b[0m\n"
    }
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Basic Feature Engineering\n",
    "Before jumping into the deepend of feature engineering, we need a base model to build off. So let's do some simple engineering:\n",
    "- Dealing with Timestamps\n",
    "- Label Encoding\n",
    "#### Timestamps"
   ]
  },
  {
   "source": [
    "# Timestamps\n",
    "clicks = click_data.copy()\n",
    "clicks['day'] = clicks['click_time'].dt.day.astype('uint8')\n",
    "clicks['hour'] = clicks['click_time'].dt.hour.astype('uint8')\n",
    "clicks['minute'] = clicks['click_time'].dt.minute.astype('uint8')\n",
    "clicks['second'] = clicks['click_time'].dt.second.astype('uint8')\n",
    "\n",
    "print(clicks.head())\n",
    ""
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ip  app  device  os  channel          click_time      attributed_time  \\\n0   89489    3       1  13      379 2017-11-06 15:13:23                  NaN   \n1  204158   35       1  13       21 2017-11-06 15:41:07  2017-11-07 08:17:19   \n2    3437    6       1  13      459 2017-11-06 15:42:32                  NaN   \n3  167543    3       1  13      379 2017-11-06 15:56:17                  NaN   \n4  147509    3       1  13      379 2017-11-06 15:57:01                  NaN   \n\n   is_attributed  day  hour  minute  second  \n0              0    6    15      13      23  \n1              1    6    15      41       7  \n2              0    6    15      42      32  \n3              0    6    15      56      17  \n4              0    6    15      57       1  \n"
    }
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Label Encoding\n",
    "For the baseline model, let's just use skikit-learn's ```LabelEncoder``` to create new features in the clicks **DataFrame**. The new columns should be the original name with *_labels* appended.\n"
   ]
  },
  {
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "for feature in cat_features:\n",
    "    encoded = encoder.fit_transform(clicks[feature])\n",
    "    clicks[feature + '_labels'] = encoded\n",
    "\n",
    "clicks.head()\n",
    ""
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       ip  app  device  os  channel          click_time      attributed_time  \\\n0   89489    3       1  13      379 2017-11-06 15:13:23                  NaN   \n1  204158   35       1  13       21 2017-11-06 15:41:07  2017-11-07 08:17:19   \n2    3437    6       1  13      459 2017-11-06 15:42:32                  NaN   \n3  167543    3       1  13      379 2017-11-06 15:56:17                  NaN   \n4  147509    3       1  13      379 2017-11-06 15:57:01                  NaN   \n\n   is_attributed  day  hour  minute  second  ip_labels  app_labels  \\\n0              0    6    15      13      23      27226           3   \n1              1    6    15      41       7     110007          35   \n2              0    6    15      42      32       1047           6   \n3              0    6    15      56      17      76270           3   \n4              0    6    15      57       1      57862           3   \n\n   device_labels  os_labels  channel_labels  \n0              1         13             120  \n1              1         13              10  \n2              1         13             157  \n3              1         13             120  \n4              1         13             120  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ip</th>\n      <th>app</th>\n      <th>device</th>\n      <th>os</th>\n      <th>channel</th>\n      <th>click_time</th>\n      <th>attributed_time</th>\n      <th>is_attributed</th>\n      <th>day</th>\n      <th>hour</th>\n      <th>minute</th>\n      <th>second</th>\n      <th>ip_labels</th>\n      <th>app_labels</th>\n      <th>device_labels</th>\n      <th>os_labels</th>\n      <th>channel_labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>89489</td>\n      <td>3</td>\n      <td>1</td>\n      <td>13</td>\n      <td>379</td>\n      <td>2017-11-06 15:13:23</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>15</td>\n      <td>13</td>\n      <td>23</td>\n      <td>27226</td>\n      <td>3</td>\n      <td>1</td>\n      <td>13</td>\n      <td>120</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>204158</td>\n      <td>35</td>\n      <td>1</td>\n      <td>13</td>\n      <td>21</td>\n      <td>2017-11-06 15:41:07</td>\n      <td>2017-11-07 08:17:19</td>\n      <td>1</td>\n      <td>6</td>\n      <td>15</td>\n      <td>41</td>\n      <td>7</td>\n      <td>110007</td>\n      <td>35</td>\n      <td>1</td>\n      <td>13</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3437</td>\n      <td>6</td>\n      <td>1</td>\n      <td>13</td>\n      <td>459</td>\n      <td>2017-11-06 15:42:32</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>15</td>\n      <td>42</td>\n      <td>32</td>\n      <td>1047</td>\n      <td>6</td>\n      <td>1</td>\n      <td>13</td>\n      <td>157</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>167543</td>\n      <td>3</td>\n      <td>1</td>\n      <td>13</td>\n      <td>379</td>\n      <td>2017-11-06 15:56:17</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>15</td>\n      <td>56</td>\n      <td>17</td>\n      <td>76270</td>\n      <td>3</td>\n      <td>1</td>\n      <td>13</td>\n      <td>120</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>147509</td>\n      <td>3</td>\n      <td>1</td>\n      <td>13</td>\n      <td>379</td>\n      <td>2017-11-06 15:57:01</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>15</td>\n      <td>57</td>\n      <td>1</td>\n      <td>57862</td>\n      <td>3</td>\n      <td>1</td>\n      <td>13</td>\n      <td>120</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train/Test/Validate Splits\n",
    "There is one thing we need to be careful with regarding our data.\n",
    "\n",
    "#### Time Series\n",
    "Our data is a *time series*. Date and time matter in regards to train and test sets. Since our model needs to predict events in the future, we must also make sure we validate the model on events in the future. If the data is mixed up between training and test sets, then future data will leak in to the model and our validationr esults will overestimate the performance on new data.\n",
    "\n",
    "Let's first sort in order of increasing time. The first 80% of rows will become the train set, the next 10% will be validation, and last 10% will be our test set."
   ]
  },
  {
   "source": [
    "base_feature_cols = ['day', 'hour', 'minute', 'second',\n",
    "                'ip_labels', 'app_labels', 'device_labels',\n",
    "                'os_labels', 'channel_labels']\n",
    "# Split implementation moved to my_modules\n",
    "base_train, base_valid, base_test = fe.get_ad_splits(clicks)"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LightGBM Training\n",
    "Now let's construct LightGBM dataset objects for each of the smaller datasets."
   ]
  },
  {
   "source": [
    "# bst, valid_score = fe.train_ad_model(base_train, base_valid, feature_cols=base_feature_cols)"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id='encode'></a>\n",
    "## <font color=blue>2. Categorical Encoding</font>\n",
    "Now let's get started by implementing some more complicated encoding and testing them using our ```train_ad_model``` function. We'll be implementing the following encodings:\n",
    "- Count Encoding\n",
    "- Target Encoding\n",
    "- CatBoost Encoding"
   ]
  },
  {
   "source": [
    "# click_data is the clean imported data\n",
    "# clicks is timestamp and label encoded\n",
    "\n",
    "# Let's do a check on unencoded data\n",
    "print(colored(\"Unencoded Model\", 'yellow'))\n",
    "train, valid, test = fe.get_ad_splits(click_data)\n",
    "unencoded_sc = fe.train_ad_model(train, valid)\n",
    "print(colored(\"Baseline Model (Timestamp + Simple Label Encoding)\", 'yellow'))\n",
    "baseline_sc = fe.train_ad_model(base_train, base_valid, feature_cols=base_feature_cols)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[33mUnencoded Model\u001b[0m\n\u001b[36mTraining model...\u001b[0m\nValidation AUC score: 0.9618\n\u001b[33mBaseline Model (Timestamp + Simple Label Encoding)\u001b[0m\n\u001b[36mTraining model...\u001b[0m\nValidation AUC score: 0.9623\n"
    }
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "source": [
    "score_dict[\"Unencoded\"] = unencoded_sc[1]\n",
    "score_dict[\"Baseline\"] = baseline_sc[1]"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Quick note on encoding and leakages\n",
    "This model were working with has calculated statistics and counts. The current columns are:\n",
    "- ip\n",
    "- app\n",
    "- device\n",
    "- os\n",
    "- channel\n",
    "- click_time\n",
    "- attributed_time\n",
    "- is_attributed (target)\n",
    "\n",
    "In regards to data leakages, we need to be careful to make sure that we calculate the encodings from ONLY the training set, to avoid overestimating the model's performance.\n",
    "\n",
    "### Count encodings\n",
    "- Count encoding is based on *replacing categories with their counts* computed on the train set.\n",
    "\n",
    "First off, let's count encode the features ```['ip', 'app', 'device', 'os', 'channel'] ``` using ```CountEncoder```. \n",
    "\n",
    "Because we need to avoid data leakage as pointed out above, we need to be sure to first **fit** *then* **transform** our data. This way, our encoding is only fit to the training data and not the valid/test sets."
   ]
  },
  {
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
    "train, valid, test = fe.get_ad_splits(clicks)\n",
    "\n",
    "# count encoder\n",
    "count_enc = ce.CountEncoder(cols=cat_features)\n",
    "\n",
    "# learn the encoding from the training set\n",
    "count_enc.fit(train[cat_features])\n",
    "\n",
    "# apply the fit encoding to the training and valid sets\n",
    "train_encoded = train.join(count_enc.transform(train[cat_features]).add_suffix('_count'))\n",
    "valid_encoded = valid.join(count_enc.transform(valid[cat_features]).add_suffix('_count'))\n",
    "\n",
    "count_sc = fe.train_ad_model(train_encoded, valid_encoded)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[36mTraining model...\u001b[0m\nValidation AUC score: 0.9650\n"
    }
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "source": [
    "score_dict[\"Count\"] = count_sc[1]\n",
    "fe.print_scores(score_dict)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[32mScores so far...\u001b[0m\nUnencoded: 0.9618\nBaseline: 0.9623\nCount: 0.9650\n\u001b[36mBest score so far: Count : 0.9650\u001b[0m\n"
    }
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Sidenote: Why is count encoding effective?\n",
    "One reason count encoding works is because rare values tend to have similar counts (with values like 1 or 2), so you can easily classify rare values together at prediction time. Common values with large counts are unlikely to have the same count as other values. So,m the common/important values get their own groupings with count encoding.\n",
    "\n",
    "### Target Encoding\n",
    "- Target encoding is the *process of replacing a categorical value with the mean of the target variable* based on the train set (be carful of data leakage).\n",
    "\n",
    "We'll be using the same ```['ip', 'app', 'device', 'os', 'channel'] ``` for target encoding the train set.\n"
   ]
  },
  {
   "source": [
    "cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
    "train, valid, test = fe.get_ad_splits(clicks)\n",
    "\n",
    "# target_encoder\n",
    "target_enc = ce.TargetEncoder(cols=cat_features)\n",
    "\n",
    "target_enc.fit(train[cat_features], train['is_attributed'])\n",
    "\n",
    "# apply the encoding\n",
    "train_encoded = train.join(target_enc.transform(train[cat_features]).add_suffix('_target'))\n",
    "valid_encoded = valid.join(target_enc.transform(valid[cat_features]).add_suffix('_target'))\n",
    "\n",
    "target_sc = fe.train_ad_model(train_encoded, valid_encoded)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[36mTraining model...\u001b[0m\nValidation AUC score: 0.9541\n"
    }
   ],
   "metadata": {},
   "execution_count": 10
  },
  {
   "source": [
    "score_dict[\"Target w/ ip\"]= target_sc[1]\n",
    "fe.print_scores(score_dict)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[32mScores so far...\u001b[0m\nUnencoded: 0.9618\nBaseline: 0.9623\nCount: 0.9650\nTarget w/ ip: 0.9541\n\u001b[36mBest score so far: Count : 0.9650\u001b[0m\n"
    }
   ],
   "metadata": {},
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Well our target score isn't as good as we had hoped. As pointed out by our great friend Kaggle, upon dropping ```ip``` from our categorical encoded features, our model actually improves. Why is that?\n",
    "\n",
    "Target encoding attemps to measure the population mean of the target for each level in the categorical feature. This means when there is less data per level, the estimated mean will be further away from the 'true' mean. There is very little data per IP address, meaning less data per level, so it's more likely that the estimates are much noisier than they should be. The model will rely heavily on this feature because of it's extremely predictive. This, in a way, overtrains our model and will perform poorly when introduced to new IP addresses. Going forward, let's leave IP out of it."
   ]
  },
  {
   "source": [
    "cat_features = ['app', 'device', 'os', 'channel']\n",
    "train, valid, test = fe.get_ad_splits(clicks)\n",
    "\n",
    "# target_encoder\n",
    "target_enc = ce.TargetEncoder(cols=cat_features)\n",
    "\n",
    "target_enc.fit(train[cat_features], train['is_attributed'])\n",
    "\n",
    "# apply the encoding\n",
    "train_encoded = train.join(target_enc.transform(train[cat_features]).add_suffix('_target'))\n",
    "valid_encoded = valid.join(target_enc.transform(valid[cat_features]).add_suffix('_target'))\n",
    "\n",
    "target_sc_no_ip = fe.train_ad_model(train_encoded, valid_encoded)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[36mTraining model...\u001b[0m\nValidation AUC score: 0.9627\n"
    }
   ],
   "metadata": {},
   "execution_count": 12
  },
  {
   "source": [
    "score_dict[\"Target w/o ip\"] = target_sc_no_ip[1]\n",
    "fe.print_scores(score_dict)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[32mScores so far...\u001b[0m\nUnencoded: 0.9618\nBaseline: 0.9623\nCount: 0.9650\nTarget w/ ip: 0.9541\nTarget w/o ip: 0.9627\n\u001b[36mBest score so far: Count : 0.9650\u001b[0m\n"
    }
   ],
   "metadata": {},
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CatBoost\n",
    "CatBoost Encoder is very similar to leave-one-out encoding, but calculates the values 'on-the-fly'. It is said to work fairly well with LightGBM.\n",
    "\n",
    "#### Sidenote: ```leave-one-out``` encoding\n",
    "```leave-one-out``` encoding is very similar to target encoding but excludes the current row's target when calculating the mean target for a level.\n"
   ]
  },
  {
   "source": [
    "cat_features = ['app', 'device', 'os', 'channel']\n",
    "train, valid, test = fe.get_ad_splits(clicks)\n",
    "\n",
    "cb_enc = ce.CatBoostEncoder(cols=cat_features)\n",
    "\n",
    "cb_enc.fit(train[cat_features], train['is_attributed'])\n",
    "\n",
    "train_encoded = train.join(cb_enc.transform(train[cat_features]).add_suffix('_cb'))\n",
    "valid_encoded = valid.join(cb_enc.transform(valid[cat_features]).add_suffix('_cb'))\n",
    "\n",
    "cb_sc = fe.train_ad_model(train_encoded, valid_encoded)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[36mTraining model...\u001b[0m\nValidation AUC score: 0.9627\n"
    }
   ],
   "metadata": {},
   "execution_count": 14
  },
  {
   "source": [
    "score_dict[\"CatBoosting\"] = cb_sc[1]\n",
    "fe.print_scores(score_dict)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[32mScores so far...\u001b[0m\nUnencoded: 0.9618\nBaseline: 0.9623\nCount: 0.9650\nTarget w/ ip: 0.9541\nTarget w/o ip: 0.9627\nCatBoosting: 0.9627\n\u001b[36mBest score so far: Count : 0.9650\u001b[0m\n"
    }
   ],
   "metadata": {},
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Results\n",
    "Out of all of the encodings we tried, 'Target w/o ip' and 'CatBoosting' performed the best. \n",
    "<a id='generate'></a>\n",
    "## 3. Generating Features\n",
    "Now let's go over some feature generation with our data (clicks).\n",
    "\n",
    "### Adding interaction features\n",
    "Let's add interaction features (combining categorical features) for each pair of categorical features (app, device, os, channel). The easiest way to accomplish this is by using ```itertools.combinations```. For each new column, we must join the values as strings with an underscore, so 13 and 47 will become ```\"13_47\"```. We also need to make sure to labelencode the new features.\n"
   ]
  },
  {
   "source": [
    "from itertools import combinations\n",
    "\n",
    "cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
    "interactions = pd.DataFrame(index=clicks.index)\n",
    "label_enc = LabelEncoder()\n",
    "for comb in combinations(cat_features, 2):\n",
    "    new_feat = comb[0] + \"_\" + comb[1]\n",
    "    interactions[new_feat]= label_enc.fit_transform(\n",
    "        clicks[comb[0]].astype(str) + \"_\" + clicks[comb[1]].astype(str)\n",
    "    )\n",
    "cprint('Label Encoded Interactions', 'cyan')\n",
    "print(interactions.head(10))\n",
    "\n",
    "clicks = clicks.join(interactions)\n",
    "cprint('Clicks w/ interactions', 'cyan')\n",
    "print(clicks.head(10))"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[36mLabel Encoded Interactions\u001b[0m\n   ip_app  ip_device   ip_os  ip_channel  app_device  app_os  app_channel  \\\n0  838251     327558  844429     1204595        3543    3973          621   \n1  324479     110989  324393      473773        3486    3715          561   \n2  590903     264762  590544      795240        4180    5063          777   \n3  219558      67781  221287      333763        3543    3973          621   \n4  163918      44449  166639      260146        3543    3973          621   \n5  765699     314168  769653     1077852        1187    1306          199   \n6  787895     318291  792428     1116302        1097    1032          154   \n7  277551      91661  278376      411425        3415    3374          507   \n8   68168      12767   70679      118063        3085    2110          318   \n9  674039     296638  674993      919684        3543    3985          610   \n\n   device_os  device_channel  os_channel  \n0        795            1534        1123  \n1        795            1465        1059  \n2        795            1570        1154  \n3        795            1534        1123  \n4        795            1534        1123  \n5        795            1450        1045  \n6        795            1534        1123  \n7        857            1578        3237  \n8        933            1449        8761  \n9        811            1463        1532  \n\u001b[36mClicks w/ interactions\u001b[0m\n       ip  app  device  os  channel          click_time      attributed_time  \\\n0   89489    3       1  13      379 2017-11-06 15:13:23                  NaN   \n1  204158   35       1  13       21 2017-11-06 15:41:07  2017-11-07 08:17:19   \n2    3437    6       1  13      459 2017-11-06 15:42:32                  NaN   \n3  167543    3       1  13      379 2017-11-06 15:56:17                  NaN   \n4  147509    3       1  13      379 2017-11-06 15:57:01                  NaN   \n5   71421   15       1  13      153 2017-11-06 16:00:00                  NaN   \n6   76953   14       1  13      379 2017-11-06 16:00:01                  NaN   \n7  187909    2       1  25      477 2017-11-06 16:00:01                  NaN   \n8  116779    1       1   8      150 2017-11-06 16:00:01                  NaN   \n9   47857    3       1  15      205 2017-11-06 16:00:01                  NaN   \n\n   is_attributed  day  hour  ...  ip_app  ip_device   ip_os  ip_channel  \\\n0              0    6    15  ...  838251     327558  844429     1204595   \n1              1    6    15  ...  324479     110989  324393      473773   \n2              0    6    15  ...  590903     264762  590544      795240   \n3              0    6    15  ...  219558      67781  221287      333763   \n4              0    6    15  ...  163918      44449  166639      260146   \n5              0    6    16  ...  765699     314168  769653     1077852   \n6              0    6    16  ...  787895     318291  792428     1116302   \n7              0    6    16  ...  277551      91661  278376      411425   \n8              0    6    16  ...   68168      12767   70679      118063   \n9              0    6    16  ...  674039     296638  674993      919684   \n\n   app_device  app_os  app_channel  device_os  device_channel  os_channel  \n0        3543    3973          621        795            1534        1123  \n1        3486    3715          561        795            1465        1059  \n2        4180    5063          777        795            1570        1154  \n3        3543    3973          621        795            1534        1123  \n4        3543    3973          621        795            1534        1123  \n5        1187    1306          199        795            1450        1045  \n6        1097    1032          154        795            1534        1123  \n7        3415    3374          507        857            1578        3237  \n8        3085    2110          318        933            1449        8761  \n9        3543    3985          610        811            1463        1532  \n\n[10 rows x 27 columns]\n"
    }
   ],
   "metadata": {},
   "execution_count": 16
  },
  {
   "source": [
    "train, valid, test = fe.get_ad_splits(clicks)\n",
    "inter_score = fe.train_ad_model(train, valid)\n",
    ""
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[36mTraining model...\u001b[0m\nValidation AUC score: 0.9624\n"
    }
   ],
   "metadata": {},
   "execution_count": 17
  },
  {
   "source": [
    "score_dict[\"Interactions\"] = inter_score[1]\n",
    "fe.print_scores(score_dict)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[32mScores so far...\u001b[0m\nUnencoded: 0.9618\nBaseline: 0.9623\nCount: 0.9650\nTarget w/ ip: 0.9541\nTarget w/o ip: 0.9627\nCatBoosting: 0.9627\nInteractions: 0.9624\n\u001b[36mBest score so far: Count : 0.9650\u001b[0m\n"
    }
   ],
   "metadata": {},
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding numerical features\n",
    "Adding interactions for categorical columns is quick and easy way to create more categorical data. It's also a good idea to add numeric features which will typically improve our model. Numerical features take a little bit of experimenting and brainstorming, but luckily our Kaggle mentors have given us ideas. \n",
    "\n",
    "#### Number of events in the past six hours\n",
    "The first feature we'll create is the number of events from the same ip in the list six hours. It's likely that someone who is visiting often will be more likely to download the app.\n",
    "\n",
    "Let's implement a function ```count_past_events``` that takes a series of click times (timestamps) and returns another Series with the number of events in the last hour."
   ]
  },
  {
   "source": [
    "def count_past_events(series):\n",
    "    \"\"\"\n",
    "    return number of events in the last hour\n",
    "        series: Series of click times (timestamps)\n",
    "    \"\"\"\n",
    "    # Assign time as the index so we can sort and roll\n",
    "    conv = pd.Series(series.index, index=series).sort_index()\n",
    "    return conv.rolling('6h').count() - 1\n",
    "\n",
    "past_events = count_past_events(clicks.click_time)\n",
    "clicks['ip_past_6hr_counts'] = past_events.values\n",
    "train, valid, _ = fe.get_ad_splits(clicks)\n",
    "num_feat_score = fe.train_ad_model(train, valid)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[36mTraining model...\u001b[0m\nValidation AUC score: 0.9619\n"
    }
   ],
   "metadata": {},
   "execution_count": 19
  },
  {
   "source": [
    "score_dict[\"Num Feature\"] = num_feat_score[1]\n",
    "fe.print_scores(score_dict)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[32mScores so far...\u001b[0m\nUnencoded: 0.9618\nBaseline: 0.9623\nCount: 0.9650\nTarget w/ ip: 0.9541\nTarget w/o ip: 0.9627\nCatBoosting: 0.9627\nInteractions: 0.9624\nNum Feature: 0.9619\n\u001b[36mBest score so far: Count : 0.9650\u001b[0m\n"
    }
   ],
   "metadata": {},
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Time since last events\n",
    "Next we'll implement a ```time_diff``` method that calculates the time since the last event in seconds from a Series of timestamps."
   ]
  },
  {
   "source": [
    "def time_diff(series):\n",
    "    \"\"\"Returns a series with the time since the last timestamp in seconds\"\"\"\n",
    "    return series.diff().dt.total_seconds()\n",
    "\n",
    "timedeltas = clicks.groupby('ip')['click_time'].transform(time_diff)\n",
    "timedeltas"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0             NaN\n1             NaN\n2             NaN\n3             NaN\n4             NaN\n            ...  \n2300556    2820.0\n2300557      22.0\n2300558      78.0\n2300559    1774.0\n2300560      23.0\nName: click_time, Length: 2300561, dtype: float64"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {},
   "execution_count": 21
  },
  {
   "source": [
    "# lets fill in NaNs with median and reindex\n",
    "timedeltas = timedeltas.fillna(timedeltas.median()).reindex(clicks.index)\n",
    "cprint('Fixed timedeltas', 'cyan')\n",
    "print(timedeltas.head(10))\n",
    "clicks['time_since_last'] = timedeltas"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[36mFixed timedeltas\u001b[0m\n0    1309.0\n1    1309.0\n2    1309.0\n3    1309.0\n4    1309.0\n5    1309.0\n6    1309.0\n7    1309.0\n8    1309.0\n9    1309.0\nName: click_time, dtype: float64\n"
    }
   ],
   "metadata": {},
   "execution_count": 22
  },
  {
   "source": [
    "train, valid, _ = fe.get_ad_splits(clicks)\n",
    "timedelta_score = fe.train_ad_model(train, valid)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[36mTraining model...\u001b[0m\nValidation AUC score: 0.9636\n"
    }
   ],
   "metadata": {},
   "execution_count": 23
  },
  {
   "source": [
    "score_dict['timedeltas'] = timedelta_score[1]\n",
    "fe.print_scores(score_dict)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[32mScores so far...\u001b[0m\nUnencoded: 0.9618\nBaseline: 0.9623\nCount: 0.9650\nTarget w/ ip: 0.9541\nTarget w/o ip: 0.9627\nCatBoosting: 0.9627\nInteractions: 0.9624\nNum Feature: 0.9619\ntimedeltas: 0.9636\n\u001b[36mBest score so far: Count : 0.9650\u001b[0m\n"
    }
   ],
   "metadata": {},
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Number of previous app downloads\n",
    "It's likely that if a visitor downlaoded an app previously, it'll affect the likelihood they'll download one again. Let's implement ```previous_attributions``` that returns a Series with the number of trimes an app has been downloaded (where ```is_attributed == 1```) before the current event."
   ]
  },
  {
   "source": [
    "# Hint: Here we want a window that always starts at the first row but expands as we get further in the data. \n",
    "# We can use the .expanding methods for this. Also, the current row is included in the window, so we need to subtract that off as well\n",
    "\n",
    "def previous_attributions(series):\n",
    "    \"\"\" returns a series with the number of previous number of downloads \"\"\"\n",
    "    return series.expanding(2).sum() - series\n",
    "\n",
    "past = previous_attributions(clicks.is_attributed)\n",
    "clicks['prev_clicks'] = past\n",
    "train, valid, _ = fe.get_ad_splits(clicks)\n",
    "prev_clicks_score = fe.train_ad_model(train, valid)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[36mTraining model...\u001b[0m\nValidation AUC score: 0.9629\n"
    }
   ],
   "metadata": {},
   "execution_count": 25
  },
  {
   "source": [
    "score_dict['prev_clicks'] = timedelta_score[1]\n",
    "fe.print_scores(score_dict)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[32mScores so far...\u001b[0m\nUnencoded: 0.9618\nBaseline: 0.9623\nCount: 0.9650\nTarget w/ ip: 0.9541\nTarget w/o ip: 0.9627\nCatBoosting: 0.9627\nInteractions: 0.9624\nNum Feature: 0.9619\ntimedeltas: 0.9636\nprev_clicks: 0.9636\n\u001b[36mBest score so far: Count : 0.9650\u001b[0m\n"
    }
   ],
   "metadata": {},
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id='select'></a>\n",
    "## 4. Feature Selection\n",
    "In this last part of our exercise, we'll use feature selection algorithms to improve our model. Let's get setup for this section.\n"
   ]
  },
  {
   "source": [
    "# inter_clicks, num_feat_clicks, time_clicks, prev_clicks\n",
    "# n = clicks.merge(inter_clicks, how='outer', suffixes=('', ''))\n",
    "train, valid, _ = fe.get_ad_splits(clicks)\n",
    "cprint('Feature Selection Baseline Score', 'cyan')\n",
    "_ = fe.train_ad_model(train, valid)\n",
    "cprint(f'Number of columns: {len(clicks.columns)}', 'green')\n",
    ""
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[36mFeature Selection Baseline Score\u001b[0m\n\u001b[36mTraining model...\u001b[0m\nValidation AUC score: 0.9629\n\u001b[32mNumber of columns: 30\u001b[0m\n"
    }
   ],
   "metadata": {},
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Moving forward, we'll want to make sure to only use the training set for selecting which features to use. Currently, our model has __ features which may cause overfitting. Removing some features will help counteract this overfitting, but may decrease the performance slightly. But at least we'll be making the model smaller and faster without losing too much performance.\n",
    "\n",
    "### Univariate Feature Selection\n",
    "Let's start by reviewing/using ```SelectKBest``` with the ```f_classif``` scoring function."
   ]
  },
  {
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# remove target-related columns and split\n",
    "feature_cols = clicks.columns.drop(['click_time', 'attributed_time', 'is_attributed'])\n",
    "train, valid, test = fe.get_ad_splits(clicks)\n",
    "\n",
    "# create the selector, let's keep 20 features\n",
    "selector = SelectKBest(f_classif, k=20)\n",
    "\n",
    "# there was a slight error with previos data, first value of prev_clicks was NaN, filling in with 0\n",
    "train['prev_clicks'][0] = 0\n",
    "\n",
    "# use selector to get the best features\n",
    "X_new = selector.fit_transform(train[feature_cols], train['is_attributed'])\n",
    "# X_new\n",
    "\n",
    "# get back the kept features as a DataFrame with the dropped columns as all 0s\n",
    "selected_features = pd.DataFrame(selector.inverse_transform(X_new),\n",
    "                                 index=train.index,\n",
    "                                 columns=feature_cols)\n",
    "# selected_features\n",
    "\n",
    "# Find the columns that were kept/dropped\n",
    "dropped_columns = selected_features.columns[selected_features.var() == 0]\n",
    "selected_features = selected_features.columns[selected_features.var() != 0]"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 28
  },
  {
   "source": [
    "cprint(f'Dropped Columns ({len(dropped_columns)})', 'blue')\n",
    "print(dropped_columns)\n",
    "cprint(f'Kept Columns ({len(selected_features)})', 'green')\n",
    "print(selected_features)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[34mDropped Columns (7)\u001b[0m\nIndex(['device', 'os', 'day', 'minute', 'second', 'os_channel',\n       'time_since_last'],\n      dtype='object')\n\u001b[32mKept Columns (20)\u001b[0m\nIndex(['ip', 'app', 'channel', 'hour', 'ip_labels', 'app_labels',\n       'device_labels', 'os_labels', 'channel_labels', 'ip_app', 'ip_device',\n       'ip_os', 'ip_channel', 'app_device', 'app_os', 'app_channel',\n       'device_os', 'device_channel', 'ip_past_6hr_counts', 'prev_clicks'],\n      dtype='object')\n"
    }
   ],
   "metadata": {},
   "execution_count": 29
  },
  {
   "source": [
    "cprint('Feature Selection KBest Score', 'cyan')\n",
    "_ = fe.train_ad_model(train.drop(dropped_columns, axis=1), valid.drop(dropped_columns, axis=1))\n",
    "cprint('Feature Selection KBest Score (Using dropped columns)', 'cyan')\n",
    "_ = fe.train_ad_model(train.drop(selected_features, axis=1), valid.drop(selected_features, axis=1)) "
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[36mFeature Selection KBest Score\u001b[0m\n\u001b[36mTraining model...\u001b[0m\nValidation AUC score: 0.9612\n\u001b[36mFeature Selection KBest Score (Using dropped columns)\u001b[0m\n\u001b[36mTraining model...\u001b[0m\nValidation AUC score: 0.9169\n"
    }
   ],
   "metadata": {},
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "With this method, we can find the bst K features, but we still have to choose K ourselves. So how do we know what is the \"best\" value of K? \n",
    "\n",
    "The solution is basically brute force. We would want to train multiple models with increasing values of K, and find which one performed the best.\n",
    "\n",
    "### L1 Regularization \n",
    "Now let's try a more powerful approach using L1 Regularization. Let's implement a function for this (```select_features_l1```) that returns a list of features to keep. This idea can be used in the real world when training a model.\n",
    "\n",
    "Let's use ```LogisticRegression``` classifier model with an L1 penalty to select the features. For the mode, let's set the random state to 7 and the regularization param to 0.1. We can fit the model then use ```SelectFromModel``` to return a model with the selected features."
   ]
  },
  {
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "def select_features_l1(X, y):\n",
    "    \"\"\" Return selected features using logistic regression with an L1 penalty \"\"\"\n",
    "    # Regularization param to 0.1, l1 penalty and random_state=7\n",
    "    log = LogisticRegression(C=0.1, penalty=\"l1\", random_state=7, verbose=1).fit(X, y)\n",
    "    \n",
    "    # Select from the model and transform\n",
    "    model = SelectFromModel(log, prefit=True)\n",
    "    X_new = model.transform(X)\n",
    "    # X_new\n",
    "\n",
    "    # Get the selected features via inverse transform\n",
    "    selected_features = pd.DataFrame(model.inverse_transform(X_new),\n",
    "                                     index=X.index,\n",
    "                                     columns=X.columns) \n",
    "\n",
    "    # Dropped columns have all 0s, keep the others\n",
    "    selected_columns = selected_features.columns[selected_features.var() != 0]\n",
    "\n",
    "    return selected_columns\n",
    "\n",
    "train, valid, _ = fe.get_ad_splits(clicks)\n",
    "train['prev_clicks'][0] = 0\n",
    "X, y = train[train.columns.drop(['click_time', 'attributed_time', 'is_attributed'])], train['is_attributed']\n",
    "selected_features = select_features_l1(X, y)\n",
    "selected_features"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/home/ttbot/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n[LibLinear]"
    }
   ],
   "metadata": {},
   "execution_count": 31
  },
  {
   "source": [
    "dropped_cols = selected_features.columns.drop(selected_features.var() == 0)\n",
    "dropped_cols"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 0
  }
 ]
}