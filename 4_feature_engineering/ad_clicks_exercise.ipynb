{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering Ad Clicks Exercise\n",
    "\n",
    "The dataset we will be using for this exercise is a sample from 'TalkingData AdTracking' Kaggle competition. All positive samples (where is_attributed == 1) was kept, while 99% of negative samples we're discarded. This sample has roughly 20% positive examples.\n",
    "The data has the following features: (note id, app, device, os, and channel are encoded).\n",
    "\n",
    "The overall goal is to predict whether a user will download an app after clicking a mobile ad.\n",
    "\n",
    "## 1. Baseline Modeling\n",
    "Using what we learned in the overview, let's setup our baseline model.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from my_modules import data_imports as data\n",
    "\n",
    "click_data = data.import_ad_clicks_data()\n",
    "click_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Basic Feature Engineering\n",
    "Before jumping into the deepend of feature engineering, we need a base model to build off. So let's do some simple engineering:\n",
    "- Dealing with Timestamps\n",
    "- Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamps\n",
    "clicks = click_data.copy()\n",
    "clicks['day'] = clicks['click_time'].dt.day.astype('uint8')\n",
    "clicks['hour'] = clicks['click_time'].dt.hour.astype('uint8')\n",
    "clicks['minute'] = clicks['click_time'].dt.minute.astype('uint8')\n",
    "clicks['second'] = clicks['click_time'].dt.second.astype('uint8')\n",
    "\n",
    "print(clicks.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Label Encoding\n",
    "For the baseline model, let's just use skikit-learn's ```LabelEncoder``` to create new features in the clicks **DataFrame**. The new columns should be the original name with *_labels* appended.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "for feature in cat_features:\n",
    "    encoded = encoder.fit_transform(clicks[feature])\n",
    "    clicks[feature + '_labels'] = encoded\n",
    "\n",
    "clicks.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train/Test/Validate Splits\n",
    "There is one thing we need to be careful with regarding our data.\n",
    "\n",
    "#### Time Series\n",
    "Our data is a *time series*. Date and time matter in regards to train and test sets. Since our model needs to predict events in the future, we must also make sure we validate the model on events in the future. If the data is mixed up between training and test sets, then future data will leak in to the model and our validationr esults will overestimate the performance on new data.\n",
    "\n",
    "Let's first sort in order of increasing time. The first 80% of rows will become the train set, the next 10% will be validation, and last 10% will be our test set."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['day', 'hour', 'minute', 'second',\n",
    "                'ip_labels', 'app_labels', 'device_labels',\n",
    "                'os_labels', 'channel_labels']\n",
    "valid_fraction = 0.1\n",
    "clicks_sorted = clicks.sort_values('click_time')\n",
    "valid_rows = int(len(clicks_sorted) * valid_fraction)\n",
    "train = clicks_sorted[ : -valid_rows * 2]\n",
    "valid = clicks_sorted[-valid_rows * 2 : -valid_rows]\n",
    "test = clicks_sorted[-valid_rows : ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LightGBM Training\n",
    "Now let's construct LightGBM dataset objects for each of the smaller datasets."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "dtrain = lgb.Dataset(train[feature_cols], label=train['is_attributed'])\n",
    "dvalid = lgb.Dataset(valid[feature_cols], label=valid['is_attributed'])\n",
    "dtest = lgb.Dataset(test[feature_cols], label=test['is_attributed'])\n",
    "\n",
    "params = {'num_leaves' : 64, 'objective' : 'binary'}\n",
    "params['metric'] = 'auc'\n",
    "num_rounds = 1000\n",
    "bst = lgb.train(params, dtrain, num_rounds, valid_sets=[dvalid], early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluatoin\n",
    "And finally let's evaluate the boss model and see how it has done."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "ypred = bst.predict(test[feature_cols])\n",
    "score = metrics.roc_auc_score(test['is_attributed'], ypred)\n",
    "print(f\"Test Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.\n"
   ]
  }
 ]
}