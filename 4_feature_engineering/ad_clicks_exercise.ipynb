{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering Ad Clicks Exercise\n",
    "\n",
    "The dataset we will be using for this exercise is a sample from 'TalkingData AdTracking' Kaggle competition. All positive samples (where is_attributed == 1) was kept, while 99% of negative samples we're discarded. This sample has roughly 20% positive examples.\n",
    "The data has the following features: (note id, app, device, os, and channel are encoded).\n",
    "\n",
    "The overall goal is to predict whether a user will download an app after clicking a mobile ad.\n",
    "\n",
    "[1. Baseline Modeling](#baseline)  \n",
    "[2. Categorical Encoding](#encode)  \n",
    "[3. Feature Generation](#generate)\n",
    "\n",
    "\n",
    "<a id='baseline'></a>\n",
    "## 1. Baseline Modeling\n",
    "Using what we learned in the overview, let's setup our baseline model.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from my_modules import data_imports as data\n",
    "from my_modules import feature_engineering as fe\n",
    "from termcolor import colored, cprint\n",
    "\n",
    "click_data = data.import_ad_clicks_data()\n",
    "click_data.head(10)\n",
    "\n",
    "score_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Basic Feature Engineering\n",
    "Before jumping into the deepend of feature engineering, we need a base model to build off. So let's do some simple engineering:\n",
    "- Dealing with Timestamps\n",
    "- Label Encoding\n",
    "#### Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamps\n",
    "clicks = click_data.copy()\n",
    "clicks['day'] = clicks['click_time'].dt.day.astype('uint8')\n",
    "clicks['hour'] = clicks['click_time'].dt.hour.astype('uint8')\n",
    "clicks['minute'] = clicks['click_time'].dt.minute.astype('uint8')\n",
    "clicks['second'] = clicks['click_time'].dt.second.astype('uint8')\n",
    "\n",
    "print(clicks.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Label Encoding\n",
    "For the baseline model, let's just use skikit-learn's ```LabelEncoder``` to create new features in the clicks **DataFrame**. The new columns should be the original name with *_labels* appended.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "for feature in cat_features:\n",
    "    encoded = encoder.fit_transform(clicks[feature])\n",
    "    clicks[feature + '_labels'] = encoded\n",
    "\n",
    "clicks.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train/Test/Validate Splits\n",
    "There is one thing we need to be careful with regarding our data.\n",
    "\n",
    "#### Time Series\n",
    "Our data is a *time series*. Date and time matter in regards to train and test sets. Since our model needs to predict events in the future, we must also make sure we validate the model on events in the future. If the data is mixed up between training and test sets, then future data will leak in to the model and our validationr esults will overestimate the performance on new data.\n",
    "\n",
    "Let's first sort in order of increasing time. The first 80% of rows will become the train set, the next 10% will be validation, and last 10% will be our test set."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_feature_cols = ['day', 'hour', 'minute', 'second',\n",
    "                'ip_labels', 'app_labels', 'device_labels',\n",
    "                'os_labels', 'channel_labels']\n",
    "# Split implementation moved to my_modules\n",
    "base_train, base_valid, base_test = fe.get_ad_splits(clicks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LightGBM Training\n",
    "Now let's construct LightGBM dataset objects for each of the smaller datasets."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bst, valid_score = fe.train_ad_model(base_train, base_valid, feature_cols=base_feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id='encode'></a>\n",
    "## <font color=blue>2. Categorical Encoding</font>\n",
    "Now let's get started by implementing some more complicated encoding and testing them using our ```train_ad_model``` function. We'll be implementing the following encodings:\n",
    "- Count Encoding\n",
    "- Target Encoding\n",
    "- CatBoost Encoding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click_data is the clean imported data\n",
    "# clicks is timestamp and label encoded\n",
    "\n",
    "# Let's do a check on unencoded data\n",
    "print(colored(\"Unencoded Model\", 'yellow'))\n",
    "train, valid, test = fe.get_ad_splits(click_data)\n",
    "unencoded_sc = fe.train_ad_model(train, valid)\n",
    "print(colored(\"Baseline Model (Timestamp + Simple Label Encoding)\", 'yellow'))\n",
    "baseline_sc = fe.train_ad_model(base_train, base_valid, feature_cols=base_feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict[\"Unencoded\"] = unencoded_sc[1]\n",
    "score_dict[\"Baseline\"] = baseline_sc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Quick note on encoding and leakages\n",
    "This model were working with has calculated statistics and counts. The current columns are:\n",
    "- ip\n",
    "- app\n",
    "- device\n",
    "- os\n",
    "- channel\n",
    "- click_time\n",
    "- attributed_time\n",
    "- is_attributed (target)\n",
    "\n",
    "In regards to data leakages, we need to be careful to make sure that we calculate the encodings from ONLY the training set, to avoid overestimating the model's performance.\n",
    "\n",
    "### Count encodings\n",
    "- Count encoding is based on *replacing categories with their counts* computed on the train set.\n",
    "\n",
    "First off, let's count encode the features ```['ip', 'app', 'device', 'os', 'channel'] ``` using ```CountEncoder```. \n",
    "\n",
    "Because we need to avoid data leakage as pointed out above, we need to be sure to first **fit** *then* **transform** our data. This way, our encoding is only fit to the training data and not the valid/test sets."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
    "train, valid, test = fe.get_ad_splits(clicks)\n",
    "\n",
    "# count encoder\n",
    "count_enc = ce.CountEncoder(cols=cat_features)\n",
    "\n",
    "# learn the encoding from the training set\n",
    "count_enc.fit(train[cat_features])\n",
    "\n",
    "# apply the fit encoding to the training and valid sets\n",
    "train_encoded = train.join(count_enc.transform(train[cat_features]).add_suffix('_count'))\n",
    "valid_encoded = valid.join(count_enc.transform(valid[cat_features]).add_suffix('_count'))\n",
    "\n",
    "count_sc = fe.train_ad_model(train_encoded, valid_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict[\"Count\"] = count_sc[1]\n",
    "fe.print_scores(score_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Sidenote: Why is count encoding effective?\n",
    "One reason count encoding works is because rare values tend to have similar counts (with values like 1 or 2), so you can easily classify rare values together at prediction time. Common values with large counts are unlikely to have the same count as other values. So,m the common/important values get their own groupings with count encoding.\n",
    "\n",
    "### Target Encoding\n",
    "- Target encoding is the *process of replacing a categorical value with the mean of the target variable* based on the train set (be carful of data leakage).\n",
    "\n",
    "We'll be using the same ```['ip', 'app', 'device', 'os', 'channel'] ``` for target encoding the train set.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
    "train, valid, test = fe.get_ad_splits(clicks)\n",
    "\n",
    "# target_encoder\n",
    "target_enc = ce.TargetEncoder(cols=cat_features)\n",
    "\n",
    "target_enc.fit(train[cat_features], train['is_attributed'])\n",
    "\n",
    "# apply the encoding\n",
    "train_encoded = train.join(target_enc.transform(train[cat_features]).add_suffix('_target'))\n",
    "valid_encoded = valid.join(target_enc.transform(valid[cat_features]).add_suffix('_target'))\n",
    "\n",
    "target_sc = fe.train_ad_model(train_encoded, valid_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict[\"Target w/ ip\"]= target_sc[1]\n",
    "fe.print_scores(score_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Well our target score isn't as good as we had hoped. As pointed out by our great friend Kaggle, upon dropping ```ip``` from our categorical encoded features, our model actually improves. Why is that?\n",
    "\n",
    "Target encoding attemps to measure the population mean of the target for each level in the categorical feature. This means when there is less data per level, the estimated mean will be further away from the 'true' mean. There is very little data per IP address, meaning less data per level, so it's more likely that the estimates are much noisier than they should be. The model will rely heavily on this feature because of it's extremely predictive. This, in a way, overtrains our model and will perform poorly when introduced to new IP addresses. Going forward, let's leave IP out of it."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['app', 'device', 'os', 'channel']\n",
    "train, valid, test = fe.get_ad_splits(clicks)\n",
    "\n",
    "# target_encoder\n",
    "target_enc = ce.TargetEncoder(cols=cat_features)\n",
    "\n",
    "target_enc.fit(train[cat_features], train['is_attributed'])\n",
    "\n",
    "# apply the encoding\n",
    "train_encoded = train.join(target_enc.transform(train[cat_features]).add_suffix('_target'))\n",
    "valid_encoded = valid.join(target_enc.transform(valid[cat_features]).add_suffix('_target'))\n",
    "\n",
    "target_sc_no_ip = fe.train_ad_model(train_encoded, valid_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict[\"Target w/o ip\"] = target_sc_no_ip[1]\n",
    "fe.print_scores(score_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CatBoost\n",
    "CatBoost Encoder is very similar to leave-one-out encoding, but calculates the values 'on-the-fly'. It is said to work fairly well with LightGBM.\n",
    "\n",
    "#### Sidenote: ```leave-one-out``` encoding\n",
    "```leave-one-out``` encoding is very similar to target encoding but excludes the current row's target when calculating the mean target for a level.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['app', 'device', 'os', 'channel']\n",
    "train, valid, test = fe.get_ad_splits(clicks)\n",
    "\n",
    "cb_enc = ce.CatBoostEncoder(cols=cat_features)\n",
    "\n",
    "cb_enc.fit(train[cat_features], train['is_attributed'])\n",
    "\n",
    "train_encoded = train.join(cb_enc.transform(train[cat_features]).add_suffix('_cb'))\n",
    "valid_encoded = valid.join(cb_enc.transform(valid[cat_features]).add_suffix('_cb'))\n",
    "\n",
    "cb_sc = fe.train_ad_model(train_encoded, valid_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict[\"CatBoosting\"] = cb_sc[1]\n",
    "fe.print_scores(score_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Results\n",
    "Out of all of the encodings we tried, 'Target w/o ip' and 'CatBoosting' performed the best. \n",
    "<a id='generate'></a>\n",
    "## 3. Generating Features\n"
   ]
  }
 ]
}