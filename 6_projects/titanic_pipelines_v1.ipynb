{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titanic Data Challenge\n",
    "\n",
    "## Introduction\n",
    "**Kaggle Description**: \n",
    "> On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n",
    "\n",
    "> While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
    "\n",
    "> In this challenge, we ask you to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc).\n",
    "\n",
    "**Goal**: To predict whether or not a passenger will survive the sinking of the Titanic based on provided information\n",
    "\n",
    "Let's begin! First, let's do some boilerplate setup."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\u001b[32mAll Modules Imported!\u001b[0m\n"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# custom helpers\n",
    "from helpers.helper import get_splits\n",
    "# data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# output\n",
    "from termcolor import cprint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cprint('All Modules Imported!', 'green')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['gender_submission.csv', 'test.csv', 'train.csv']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\u001b[32mData Imported!\u001b[0m\n\u001b[36mTraining Data Example:\u001b[0m\n"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>887</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Montvila, Rev. Juozas</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>211536</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Graham, Miss. Margaret Edith</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112053</td>\n      <td>30.0000</td>\n      <td>B42</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <td>889</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>W./C. 6607</td>\n      <td>23.4500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <td>890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Behr, Mr. Karl Howell</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111369</td>\n      <td>30.0000</td>\n      <td>C148</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <td>891</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Dooley, Mr. Patrick</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>370376</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows × 11 columns</p>\n</div>",
      "text/plain": "             Survived  Pclass  \\\nPassengerId                     \n1                   0       3   \n2                   1       1   \n3                   1       3   \n4                   1       1   \n5                   0       3   \n...               ...     ...   \n887                 0       2   \n888                 1       1   \n889                 0       3   \n890                 1       1   \n891                 0       3   \n\n                                                          Name     Sex   Age  \\\nPassengerId                                                                    \n1                                      Braund, Mr. Owen Harris    male  22.0   \n2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n3                                       Heikkinen, Miss. Laina  female  26.0   \n4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n5                                     Allen, Mr. William Henry    male  35.0   \n...                                                        ...     ...   ...   \n887                                      Montvila, Rev. Juozas    male  27.0   \n888                               Graham, Miss. Margaret Edith  female  19.0   \n889                   Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN   \n890                                      Behr, Mr. Karl Howell    male  26.0   \n891                                        Dooley, Mr. Patrick    male  32.0   \n\n             SibSp  Parch            Ticket     Fare Cabin Embarked  \nPassengerId                                                          \n1                1      0         A/5 21171   7.2500   NaN        S  \n2                1      0          PC 17599  71.2833   C85        C  \n3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n4                1      0            113803  53.1000  C123        S  \n5                0      0            373450   8.0500   NaN        S  \n...            ...    ...               ...      ...   ...      ...  \n887              0      0            211536  13.0000   NaN        S  \n888              0      0            112053  30.0000   B42        S  \n889              1      2        W./C. 6607  23.4500   NaN        S  \n890              0      0            111369  30.0000  C148        C  \n891              0      0            370376   7.7500   NaN        Q  \n\n[891 rows x 11 columns]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = pd.read_csv('./data/train.csv', index_col='PassengerId')\n",
    "test_data = pd.read_csv('./data/test.csv', index_col='PassengerId')\n",
    "\n",
    "cprint('Data Imported!', 'green')\n",
    "cprint('Training Data Example:', 'cyan')\n",
    "display(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Process\n",
    "1. Figure out which features we can safely drop/keep.\n",
    "2. Encode features that need encoding (label encoding, categorical encoding).\n",
    "3. Start feature engineering some new columns so we have a wider predicition set. \n",
    "4. Do feature selection to determine which features are not needed and find the best combination of features to use.\n",
    "5. Research and test what models would be best for our situation and train/test different models.\n",
    "6. Train and predict on the train/test sets.\n",
    "7. Finally, output everything to a new CSV.\n",
    "\n",
    "## Tools\n",
    "Our current model options are: LightGBM, RandomForestRegressor, ExtraTreesRegressor.\n",
    "\n",
    "I also want to use a pipeline to keep everything organized into various steps.\n",
    "\n",
    "\n",
    "## Getting Started\n",
    "### Feature Engineering\n",
    "So the columns we have are:\n",
    "\n",
    "| Variable | Definition | Key |\n",
    "| ----- | --- | --- |\n",
    "| survival | Survived or not | 0 = No, 1 = Yes |\n",
    "| pclass | Ticket class | 1 = 1st, 2 = 2nd, 3 = 3rd |\n",
    "| sex | Sex | |\n",
    "| age | Age in years | |\n",
    "| sibsp | Num of siblings / spouses aboard | |\n",
    "| parch | Num of parents / children aboard | |\n",
    "| ticket | Ticket number | |\n",
    "| fare | Passengar fare | |\n",
    "| cabin | Cabin number | |\n",
    "| embarked | Port of embarkation |   C = Cherbourg, Q = Queenstown, S = Southampton |\n",
    "\n",
    "Looking at these descriptions, we can probably disregard\n",
    "- Name\n",
    "- Ticket number\n",
    "\n",
    "Ticket number is a ... maybe, as we aren't entirely sure how ticket numbers are handed out.\n",
    "\n",
    "Let's get to engineering.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Createion Steps\n",
    "1. [x] Choose feature cols based on feature table and relevant data\n",
    "2. [x] Split into train/valid/test sets\n",
    "3. [ ] Generate features\n",
    "    1. Interactions\n",
    "    2. ...\n",
    "4. [ ] Setup pipeline\n",
    "    1. [x] Imputation to fill in N/A values\n",
    "    2. [x] Categorical encoding, CatBoost\n",
    "    4. [x] Standardize values\n",
    "    5. [ ] Feature Selection\n",
    "5. [ ] Train"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature Generation / Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Pclass_Sex</th>\n      <th>Pclass_Cabin</th>\n      <th>Pclass_Embarked</th>\n      <th>Sex_Cabin</th>\n      <th>Sex_Embarked</th>\n      <th>Cabin_Embarked</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>3_male</td>\n      <td>3_nan</td>\n      <td>3_S</td>\n      <td>male_nan</td>\n      <td>male_S</td>\n      <td>nan_S</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n      <td>1_female</td>\n      <td>1_C85</td>\n      <td>1_C</td>\n      <td>female_C85</td>\n      <td>female_C</td>\n      <td>C85_C</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>3_female</td>\n      <td>3_nan</td>\n      <td>3_S</td>\n      <td>female_nan</td>\n      <td>female_S</td>\n      <td>nan_S</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n      <td>1_female</td>\n      <td>1_C123</td>\n      <td>1_S</td>\n      <td>female_C123</td>\n      <td>female_S</td>\n      <td>C123_S</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>3_male</td>\n      <td>3_nan</td>\n      <td>3_S</td>\n      <td>male_nan</td>\n      <td>male_S</td>\n      <td>nan_S</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>887</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Montvila, Rev. Juozas</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>211536</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>2_male</td>\n      <td>2_nan</td>\n      <td>2_S</td>\n      <td>male_nan</td>\n      <td>male_S</td>\n      <td>nan_S</td>\n    </tr>\n    <tr>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Graham, Miss. Margaret Edith</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112053</td>\n      <td>30.0000</td>\n      <td>B42</td>\n      <td>S</td>\n      <td>1_female</td>\n      <td>1_B42</td>\n      <td>1_S</td>\n      <td>female_B42</td>\n      <td>female_S</td>\n      <td>B42_S</td>\n    </tr>\n    <tr>\n      <td>889</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>W./C. 6607</td>\n      <td>23.4500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>3_female</td>\n      <td>3_nan</td>\n      <td>3_S</td>\n      <td>female_nan</td>\n      <td>female_S</td>\n      <td>nan_S</td>\n    </tr>\n    <tr>\n      <td>890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Behr, Mr. Karl Howell</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111369</td>\n      <td>30.0000</td>\n      <td>C148</td>\n      <td>C</td>\n      <td>1_male</td>\n      <td>1_C148</td>\n      <td>1_C</td>\n      <td>male_C148</td>\n      <td>male_C</td>\n      <td>C148_C</td>\n    </tr>\n    <tr>\n      <td>891</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Dooley, Mr. Patrick</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>370376</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n      <td>3_male</td>\n      <td>3_nan</td>\n      <td>3_Q</td>\n      <td>male_nan</td>\n      <td>male_Q</td>\n      <td>nan_Q</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows × 17 columns</p>\n</div>",
      "text/plain": "             Survived  Pclass  \\\nPassengerId                     \n1                   0       3   \n2                   1       1   \n3                   1       3   \n4                   1       1   \n5                   0       3   \n...               ...     ...   \n887                 0       2   \n888                 1       1   \n889                 0       3   \n890                 1       1   \n891                 0       3   \n\n                                                          Name     Sex   Age  \\\nPassengerId                                                                    \n1                                      Braund, Mr. Owen Harris    male  22.0   \n2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n3                                       Heikkinen, Miss. Laina  female  26.0   \n4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n5                                     Allen, Mr. William Henry    male  35.0   \n...                                                        ...     ...   ...   \n887                                      Montvila, Rev. Juozas    male  27.0   \n888                               Graham, Miss. Margaret Edith  female  19.0   \n889                   Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN   \n890                                      Behr, Mr. Karl Howell    male  26.0   \n891                                        Dooley, Mr. Patrick    male  32.0   \n\n             SibSp  Parch            Ticket     Fare Cabin Embarked  \\\nPassengerId                                                           \n1                1      0         A/5 21171   7.2500   NaN        S   \n2                1      0          PC 17599  71.2833   C85        C   \n3                0      0  STON/O2. 3101282   7.9250   NaN        S   \n4                1      0            113803  53.1000  C123        S   \n5                0      0            373450   8.0500   NaN        S   \n...            ...    ...               ...      ...   ...      ...   \n887              0      0            211536  13.0000   NaN        S   \n888              0      0            112053  30.0000   B42        S   \n889              1      2        W./C. 6607  23.4500   NaN        S   \n890              0      0            111369  30.0000  C148        C   \n891              0      0            370376   7.7500   NaN        Q   \n\n            Pclass_Sex Pclass_Cabin Pclass_Embarked    Sex_Cabin Sex_Embarked  \\\nPassengerId                                                                     \n1               3_male        3_nan             3_S     male_nan       male_S   \n2             1_female        1_C85             1_C   female_C85     female_C   \n3             3_female        3_nan             3_S   female_nan     female_S   \n4             1_female       1_C123             1_S  female_C123     female_S   \n5               3_male        3_nan             3_S     male_nan       male_S   \n...                ...          ...             ...          ...          ...   \n887             2_male        2_nan             2_S     male_nan       male_S   \n888           1_female        1_B42             1_S   female_B42     female_S   \n889           3_female        3_nan             3_S   female_nan     female_S   \n890             1_male       1_C148             1_C    male_C148       male_C   \n891             3_male        3_nan             3_Q     male_nan       male_Q   \n\n            Cabin_Embarked  \nPassengerId                 \n1                    nan_S  \n2                    C85_C  \n3                    nan_S  \n4                   C123_S  \n5                    nan_S  \n...                    ...  \n887                  nan_S  \n888                  B42_S  \n889                  nan_S  \n890                 C148_C  \n891                  nan_Q  \n\n[891 rows x 17 columns]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Pclass_Sex</th>\n      <th>Pclass_Cabin</th>\n      <th>Pclass_Embarked</th>\n      <th>Sex_Cabin</th>\n      <th>Sex_Embarked</th>\n      <th>Cabin_Embarked</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>3_male</td>\n      <td>3_nan</td>\n      <td>3_S</td>\n      <td>male_nan</td>\n      <td>male_S</td>\n      <td>nan_S</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n      <td>1_female</td>\n      <td>1_C85</td>\n      <td>1_C</td>\n      <td>female_C85</td>\n      <td>female_C</td>\n      <td>C85_C</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>3_female</td>\n      <td>3_nan</td>\n      <td>3_S</td>\n      <td>female_nan</td>\n      <td>female_S</td>\n      <td>nan_S</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n      <td>1_female</td>\n      <td>1_C123</td>\n      <td>1_S</td>\n      <td>female_C123</td>\n      <td>female_S</td>\n      <td>C123_S</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>3_male</td>\n      <td>3_nan</td>\n      <td>3_S</td>\n      <td>male_nan</td>\n      <td>male_S</td>\n      <td>nan_S</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>709</td>\n      <td>1</td>\n      <td>Cleaver, Miss. Alice</td>\n      <td>female</td>\n      <td>22.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>113781</td>\n      <td>151.5500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>1_female</td>\n      <td>1_nan</td>\n      <td>1_S</td>\n      <td>female_nan</td>\n      <td>female_S</td>\n      <td>nan_S</td>\n    </tr>\n    <tr>\n      <td>710</td>\n      <td>3</td>\n      <td>Moubarek, Master. Halim Gonios (\"William George\")</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2661</td>\n      <td>15.2458</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>3_male</td>\n      <td>3_nan</td>\n      <td>3_C</td>\n      <td>male_nan</td>\n      <td>male_C</td>\n      <td>nan_C</td>\n    </tr>\n    <tr>\n      <td>711</td>\n      <td>1</td>\n      <td>Mayne, Mlle. Berthe Antonine (\"Mrs de Villiers\")</td>\n      <td>female</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>PC 17482</td>\n      <td>49.5042</td>\n      <td>C90</td>\n      <td>C</td>\n      <td>1_female</td>\n      <td>1_C90</td>\n      <td>1_C</td>\n      <td>female_C90</td>\n      <td>female_C</td>\n      <td>C90_C</td>\n    </tr>\n    <tr>\n      <td>712</td>\n      <td>1</td>\n      <td>Klaber, Mr. Herman</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>113028</td>\n      <td>26.5500</td>\n      <td>C124</td>\n      <td>S</td>\n      <td>1_male</td>\n      <td>1_C124</td>\n      <td>1_S</td>\n      <td>male_C124</td>\n      <td>male_S</td>\n      <td>C124_S</td>\n    </tr>\n    <tr>\n      <td>713</td>\n      <td>1</td>\n      <td>Taylor, Mr. Elmer Zebley</td>\n      <td>male</td>\n      <td>48.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>19996</td>\n      <td>52.0000</td>\n      <td>C126</td>\n      <td>S</td>\n      <td>1_male</td>\n      <td>1_C126</td>\n      <td>1_S</td>\n      <td>male_C126</td>\n      <td>male_S</td>\n      <td>C126_S</td>\n    </tr>\n  </tbody>\n</table>\n<p>713 rows × 16 columns</p>\n</div>",
      "text/plain": "             Pclass                                               Name  \\\nPassengerId                                                              \n1                 3                            Braund, Mr. Owen Harris   \n2                 1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n3                 3                             Heikkinen, Miss. Laina   \n4                 1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n5                 3                           Allen, Mr. William Henry   \n...             ...                                                ...   \n709               1                               Cleaver, Miss. Alice   \n710               3  Moubarek, Master. Halim Gonios (\"William George\")   \n711               1   Mayne, Mlle. Berthe Antonine (\"Mrs de Villiers\")   \n712               1                                 Klaber, Mr. Herman   \n713               1                           Taylor, Mr. Elmer Zebley   \n\n                Sex   Age  SibSp  Parch            Ticket      Fare Cabin  \\\nPassengerId                                                                 \n1              male  22.0      1      0         A/5 21171    7.2500   NaN   \n2            female  38.0      1      0          PC 17599   71.2833   C85   \n3            female  26.0      0      0  STON/O2. 3101282    7.9250   NaN   \n4            female  35.0      1      0            113803   53.1000  C123   \n5              male  35.0      0      0            373450    8.0500   NaN   \n...             ...   ...    ...    ...               ...       ...   ...   \n709          female  22.0      0      0            113781  151.5500   NaN   \n710            male   NaN      1      1              2661   15.2458   NaN   \n711          female  24.0      0      0          PC 17482   49.5042   C90   \n712            male   NaN      0      0            113028   26.5500  C124   \n713            male  48.0      1      0             19996   52.0000  C126   \n\n            Embarked Pclass_Sex Pclass_Cabin Pclass_Embarked    Sex_Cabin  \\\nPassengerId                                                                 \n1                  S     3_male        3_nan             3_S     male_nan   \n2                  C   1_female        1_C85             1_C   female_C85   \n3                  S   3_female        3_nan             3_S   female_nan   \n4                  S   1_female       1_C123             1_S  female_C123   \n5                  S     3_male        3_nan             3_S     male_nan   \n...              ...        ...          ...             ...          ...   \n709                S   1_female        1_nan             1_S   female_nan   \n710                C     3_male        3_nan             3_C     male_nan   \n711                C   1_female        1_C90             1_C   female_C90   \n712                S     1_male       1_C124             1_S    male_C124   \n713                S     1_male       1_C126             1_S    male_C126   \n\n            Sex_Embarked Cabin_Embarked  \nPassengerId                              \n1                 male_S          nan_S  \n2               female_C          C85_C  \n3               female_S          nan_S  \n4               female_S         C123_S  \n5                 male_S          nan_S  \n...                  ...            ...  \n709             female_S          nan_S  \n710               male_C          nan_C  \n711             female_C          C90_C  \n712               male_S         C124_S  \n713               male_S         C126_S  \n\n[713 rows x 16 columns]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Choose our feature cols based on feature table above\n",
    "numerical_cols = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "categorical_cols = ['Pclass', 'Sex', 'Cabin', 'Embarked']\n",
    "target_col = 'Survived'\n",
    "# Let's make some features\n",
    "from itertools import combinations\n",
    "\n",
    "interactions = pd.DataFrame(index=train_data.index)\n",
    "for comb in combinations(categorical_cols, 2):\n",
    "    new_feat = comb[0] + \"_\" + comb[1]\n",
    "    interactions[new_feat] = train_data[comb[0]].astype(str) + \"_\" + train_data[comb[1]].astype(str)\n",
    "    categorical_cols.append(new_feat)\n",
    "train_data = train_data.join(interactions)\n",
    "display(train_data)\n",
    "# 2. Split sets\n",
    "train, valid, _ = get_splits(train_data)\n",
    "X_train = train.drop([target_col], axis=1)\n",
    "y_train = train[target_col]\n",
    "X_valid = valid.drop([target_col], axis=1)\n",
    "y_valid = valid[target_col]\n",
    "display(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning\n",
    "from sklearn import feature_selection\n",
    "from sklearn import preprocessing\n",
    "# Pipeline code originally copied from 3_intermediate_training_summary\n",
    "from helpers.helper import PipelineFS\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# conda install -c conda-forge category_encoders\n",
    "from category_encoders import CatBoostEncoder\n",
    "# conda install -c conda-forge lightgbm\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lgb_pipeline_score(X, y, params={'n_estimators':10,'num_leaves':64,'rate':0.1,'early_stopping_rounds':10}):\n",
    "    \"\"\"\n",
    "    Run LightBGM pipeline on the provided parameters. \n",
    "    Scores based on cross_validation with 5 folds.\n",
    "\n",
    "    params: Python object of params with the following keys\n",
    "        n_estimators: number of estimators to use in pipeline, Default: 10\n",
    "        num_leaves: num_leaves in lgb model, Default: 64\n",
    "        rate: learning rate, Default: 0.1\n",
    "        early_stopping_rounds: how many rounds to stop after if low variance, Default: 10\n",
    "    \"\"\"\n",
    "    # Preprocessing for numerical data (fill in NA)\n",
    "    numerical_transformer = PipelineFS(\n",
    "        steps=[\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Preprocessing for categorical data\n",
    "    categorical_transformer = PipelineFS(\n",
    "        steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('catboost', CatBoostEncoder())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Bundle preprocessing for numerical and categorical data\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model = lgb.LGBMClassifier(n_estimators=params['n_estimators'], num_leaves=params['num_leaves'], learning_rate=params['rate'])\n",
    "\n",
    "    # Bundle preprocessing and modeling code in a pipeline\n",
    "    my_pipeline = PipelineFS(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', model)\n",
    "        ],\n",
    "        verbose=False\n",
    "    )\n",
    "    # Preprocessing of training data, fit model \n",
    "    # my_pipeline.fit(X_train, y_train)\n",
    "    # cprint('Fit!', 'green')\n",
    "    # Preprocessing of validation data, get predictions\n",
    "    scores = cross_val_score(my_pipeline, X, y, cv=5)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n<class 'helpers.helper.PipelineFS'>\n{50: 0.7349699945444625, 100: 0.729375588950057, 150: 0.7433814412537817, 200: 0.7377870356593761, 250: 0.7433814412537817, 300: 0.7364082725784853, 350: 0.736368595943064, 400: 0.7307741903486584, 450: 0.7349699945444627, 500: 0.7307741903486584, 550: 0.727957149233745, 600: 0.7279373109160344, 650: 0.7265387095174329, 700: 0.7335713931458612, 750: 0.7307543520309479, 800: 0.729375588950057, 850: 0.7321926300649706, 900: 0.7279769875514556, 950: 0.7265783861528543, 1000: 0.729375588950057}\n"
    }
   ],
   "source": [
    "# get_lgb_pipeline_score(X_train, y_train)\n",
    "\n",
    "results = {}\n",
    "params={'n_estimators':10,'num_leaves':64,'rate':0.1,'early_stopping_rounds':10}\n",
    "for i in range(50, 1001, 50):\n",
    "    params['n_estimators'] = i\n",
    "    results[i] = get_lgb_pipeline_score(X_train, y_train, params=params)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Basic steps for the future\n",
    "- Deal with missing values\n",
    "- Deal with zeroes\n",
    "- Encoding categorical variables\n",
    "- Creating new features\n",
    "    - Interactions\n",
    "- Transforming features\n",
    "    - Normalization/Outliers\n",
    "- Feature Analysis\n",
    "    - Feature types\n",
    "    - How feature correlates to target\n",
    "    - Graphs Graphs Graphs\n",
    "- Model fitting\n",
    "    - outlier removal\n",
    "    - optimization\n",
    "\n",
    "Also, should we use **Pipelines** from now on?\n",
    "- [ ] Yes\n",
    "- [ ] No"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes from example kernel\n",
    "So far so good, but compared to others...not great. Below are some notes after looking at some example kernels.\n",
    "\n",
    "- Combine the train and test data sets into a single dataframe to make feature transformation easier.\n",
    "    - Get the ids (indexes) of both the test and train sets so that they can be extracted again later.\n",
    "- When filling in N/A values, be sure to figure out what N/A ACTUALLY means. Do we need to persist that value as something else? ie, in housing data, if garage is N/A, that just means the house doesn't have a garage, which is data we want to persist \n",
    "- When creating features, it takes a little brain/common sense to figure out interactions. One way is to yes, just create a ton, but for finding INTERESTING interactions, you really gotta sit and think.\n",
    "    - For example, with the housing data, instead of just comparing different area values. Large properties will have large areas with high sale prices by default. But what is more intersting maybe is the *fraction* of the base that is of each different room type.\n",
    "- *GRAPHS*\n",
    "    - USE SCATTERPLOTS. They are amazing for visualizing the correlation of a feature vs target.\n",
    "    - Same as above, GRAPH GRAPH GRAPH. Another useful graph is graphing the different means of the target. This can help to find outliers.\n",
    "    - Correlation. How do the current features correlate to the target?\n",
    "- Optmization tricks: \n",
    "    - use a model to predict values for filling in NaN\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}